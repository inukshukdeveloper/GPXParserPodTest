{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pix2Pix-TF-0.9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "swift",
      "display_name": "Swift"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inukshukdeveloper/GPXParserPodTest/blob/master/Pix2Pix_TF_0_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOavVZ_vbh-6",
        "colab_type": "text"
      },
      "source": [
        "# example of pix2pix gan for satellite to map image-to-image translation\n",
        "from numpy import load\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import randint\n",
        "from keras.optimizers import Adam\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.models import Model\n",
        "from keras.models import Input\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# define the discriminator model\n",
        "def define_discriminator(image_shape):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# source image input\n",
        "\tin_src_image = Input(shape=image_shape)\n",
        "\t# target image input\n",
        "\tin_target_image = Input(shape=image_shape)\n",
        "\t# concatenate images channel-wise\n",
        "\tmerged = Concatenate()([in_src_image, in_target_image])\n",
        "\t# C64\n",
        "\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# C128\n",
        "\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = BatchNormalization()(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# C256\n",
        "\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = BatchNormalization()(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# C512\n",
        "\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = BatchNormalization()(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# second last output layer\n",
        "\td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
        "\td = BatchNormalization()(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# patch output\n",
        "\td = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
        "\tpatch_out = Activation('sigmoid')(d)\n",
        "\t# define model\n",
        "\tmodel = Model([in_src_image, in_target_image], patch_out)\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
        "\treturn model\n",
        "\n",
        "# define an encoder block\n",
        "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# add downsampling layer\n",
        "\tg = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
        "\t# conditionally add batch normalization\n",
        "\tif batchnorm:\n",
        "\t\tg = BatchNormalization()(g, training=True)\n",
        "\t# leaky relu activation\n",
        "\tg = LeakyReLU(alpha=0.2)(g)\n",
        "\treturn g\n",
        "\n",
        "# define a decoder block\n",
        "def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# add upsampling layer\n",
        "\tg = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
        "\t# add batch normalization\n",
        "\tg = BatchNormalization()(g, training=True)\n",
        "\t# conditionally add dropout\n",
        "\tif dropout:\n",
        "\t\tg = Dropout(0.5)(g, training=True)\n",
        "\t# merge with skip connection\n",
        "\tg = Concatenate()([g, skip_in])\n",
        "\t# relu activation\n",
        "\tg = Activation('relu')(g)\n",
        "\treturn g\n",
        "\n",
        "# define the standalone generator model\n",
        "def define_generator(image_shape=(256,256,3)):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# image input\n",
        "\tin_image = Input(shape=image_shape)\n",
        "\t# encoder model\n",
        "\te1 = define_encoder_block(in_image, 64, batchnorm=False)\n",
        "\te2 = define_encoder_block(e1, 128)\n",
        "\te3 = define_encoder_block(e2, 256)\n",
        "\te4 = define_encoder_block(e3, 512)\n",
        "\te5 = define_encoder_block(e4, 512)\n",
        "\te6 = define_encoder_block(e5, 512)\n",
        "\te7 = define_encoder_block(e6, 512)\n",
        "\t# bottleneck, no batch norm and relu\n",
        "\tb = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n",
        "\tb = Activation('relu')(b)\n",
        "\t# decoder model\n",
        "\td1 = decoder_block(b, e7, 512)\n",
        "\td2 = decoder_block(d1, e6, 512)\n",
        "\td3 = decoder_block(d2, e5, 512)\n",
        "\td4 = decoder_block(d3, e4, 512, dropout=False)\n",
        "\td5 = decoder_block(d4, e3, 256, dropout=False)\n",
        "\td6 = decoder_block(d5, e2, 128, dropout=False)\n",
        "\td7 = decoder_block(d6, e1, 64, dropout=False)\n",
        "\t# output\n",
        "\tg = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n",
        "\tout_image = Activation('tanh')(g)\n",
        "\t# define model\n",
        "\tmodel = Model(in_image, out_image)\n",
        "\treturn model\n",
        "\n",
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(g_model, d_model, image_shape):\n",
        "\t# make weights in the discriminator not trainable\n",
        "\td_model.trainable = False\n",
        "\t# define the source image\n",
        "\tin_src = Input(shape=image_shape)\n",
        "\t# connect the source image to the generator input\n",
        "\tgen_out = g_model(in_src)\n",
        "\t# connect the source input and generator output to the discriminator input\n",
        "\tdis_out = d_model([in_src, gen_out])\n",
        "\t# src image as input, generated image and classification output\n",
        "\tmodel = Model(in_src, [dis_out, gen_out])\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n",
        "\treturn model\n",
        "\n",
        "\n",
        "# load and prepare training images\n",
        "def load_real_samples(filename):\n",
        "\t# load compressed arrays\n",
        "\tdata = load(filename)\n",
        "\t# unpack arrays\n",
        "\tX1, X2 = data['arr_0'], data['arr_1']\n",
        "\t# scale from [0,255] to [-1,1]\n",
        "\tX1 = (X1 - 127.5) / 127.5\n",
        "\tX2 = (X2 - 127.5) / 127.5\n",
        "\treturn [X1, X2]\n",
        "\n",
        "# select a batch of random samples, returns images and target\n",
        "def generate_real_samples(dataset, n_samples, patch_shape):\n",
        "\t# unpack dataset\n",
        "\ttrainA, trainB = dataset\n",
        "\t# choose random instances\n",
        "\tix = randint(0, trainA.shape[0], n_samples)\n",
        "\t# retrieve selected images\n",
        "\tX1, X2 = trainA[ix], trainB[ix]\n",
        "\t# generate 'real' class labels (1)\n",
        "\ty = ones((n_samples, patch_shape, patch_shape, 1))\n",
        "\treturn [X1, X2], y\n",
        "\n",
        "# generate a batch of images, returns images and targets\n",
        "def generate_fake_samples(g_model, samples, patch_shape):\n",
        "\t# generate fake instance\n",
        "\tX = g_model.predict(samples)\n",
        "\t# create 'fake' class labels (0)\n",
        "\ty = zeros((len(X), patch_shape, patch_shape, 1))\n",
        "\treturn X, y\n",
        "\n",
        "# generate samples and save as a plot and save the model\n",
        "def summarize_performance(step, g_model, dataset, n_samples=3):\n",
        "\t# select a sample of input images\n",
        "\t[X_realA, X_realB], _ = generate_real_samples(dataset, n_samples, 1)\n",
        "\t# generate a batch of fake samples\n",
        "\tX_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n",
        "\t# scale all pixels from [-1,1] to [0,1]\n",
        "\tX_realA = (X_realA + 1) / 2.0\n",
        "\tX_realB = (X_realB + 1) / 2.0\n",
        "\tX_fakeB = (X_fakeB + 1) / 2.0\n",
        "\t# plot real source images\n",
        "\tfor i in range(n_samples):\n",
        "\t\tpyplot.subplot(3, n_samples, 1 + i)\n",
        "\t\tpyplot.axis('off')\n",
        "\t\tpyplot.imshow(X_realA[i])\n",
        "\t# plot generated target image\n",
        "\tfor i in range(n_samples):\n",
        "\t\tpyplot.subplot(3, n_samples, 1 + n_samples + i)\n",
        "\t\tpyplot.axis('off')\n",
        "\t\tpyplot.imshow(X_fakeB[i])\n",
        "\t# plot real target image\n",
        "\tfor i in range(n_samples):\n",
        "\t\tpyplot.subplot(3, n_samples, 1 + n_samples*2 + i)\n",
        "\t\tpyplot.axis('off')\n",
        "\t\tpyplot.imshow(X_realB[i])\n",
        "\t# save plot to file\n",
        "\tfilename1 = 'plot_%06d.png' % (step+1)\n",
        "\tpyplot.savefig(filename1)\n",
        "\tpyplot.close()\n",
        "\t# save the generator model\n",
        "\tfilename2 = 'model_%06d.h5' % (step+1)\n",
        "\tg_model.save(filename2)\n",
        "\tprint('>Saved: %s and %s' % (filename1, filename2))\n",
        "\n",
        "# train pix2pix models\n",
        "def train(d_model, g_model, gan_model, dataset, n_epochs=100, n_batch=1):\n",
        "\t# determine the output square shape of the discriminator\n",
        "\tn_patch = d_model.output_shape[1]\n",
        "\t# unpack dataset\n",
        "\ttrainA, trainB = dataset\n",
        "\t# calculate the number of batches per training epoch\n",
        "\tbat_per_epo = int(len(trainA) / n_batch)\n",
        "\t# calculate the number of training iterations\n",
        "\tn_steps = bat_per_epo * n_epochs\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_steps):\n",
        "\t\t# select a batch of real samples\n",
        "\t\t[X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\n",
        "\t\t# generate a batch of fake samples\n",
        "\t\tX_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
        "\t\t# update discriminator for real samples\n",
        "\t\td_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
        "\t\t# update discriminator for generated samples\n",
        "\t\td_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
        "\t\t# update the generator\n",
        "\t\tg_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
        "\t\t# summarize performance\n",
        "\t\tprint('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\n",
        "\t\t# summarize model performance\n",
        "\t\tif (i+1) % (bat_per_epo * 10) == 0:\n",
        "\t\t\tsummarize_performance(i, g_model, dataset)\n",
        "\n",
        "# load image data\n",
        "dataset = load_real_samples('maps_256.npz')\n",
        "print('Loaded', dataset[0].shape, dataset[1].shape)\n",
        "# define input shape based on the loaded dataset\n",
        "image_shape = dataset[0].shape[1:]\n",
        "# define the models\n",
        "d_model = define_discriminator(image_shape)\n",
        "g_model = define_generator(image_shape)\n",
        "# define the composite model\n",
        "gan_model = define_gan(g_model, d_model, image_shape)\n",
        "# train model\n",
        "train(d_model, g_model, gan_model, dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxFuTj0DblI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// Start translation of Pix2Pix from Python to Swift"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT1hYyTOSCJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%install '.package(url: \"https://github.com/inukshukdeveloper/swift-models\", .branch(\"Add_Tar_Extension\"))' ImageClassificationModels Datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcIipp1lWsHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Foundation\n",
        "import ModelSupport\n",
        "import TensorFlow\n",
        "import Batcher\n",
        "import ImageClassificationModels\n",
        "import Datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux372R8RkDUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "struct Stack<Element> {\n",
        "    var items = [Element]()\n",
        "    mutating func push(_ item: Element) {\n",
        "        items.append(item)\n",
        "    }\n",
        "    mutating func pop() -> Element {\n",
        "        return items.removeLast()\n",
        "    }\n",
        "    public init(elements: [Element]) {\n",
        "      items = elements\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb0QMqo9kRF6",
        "colab_type": "code",
        "outputId": "f8c15e1d-75d2-44b2-8516-5a0a70239a2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "var stack = Stack(elements: [1,2,3,4,5])\n",
        "var stack2: Stack<Int32> = Stack(elements: [Int32]())\n",
        "print(\"stack top\", stack.pop())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stack top 5\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7dvM_XbTqbm",
        "colab_type": "code",
        "outputId": "0524086c-ec74-49d8-d69c-7a40b6352049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "// comment so that Colab does not interpret `#if ...` as a comment\n",
        "#if canImport(PythonKit)\n",
        "    import PythonKit\n",
        "#else\n",
        "    import Python\n",
        "#endif\n",
        "print(Python.version)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.6.9 (default, Apr 18 2020, 01:56:04) \r\n",
            "[GCC 8.4.0]\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejVNNL5aTbIL",
        "colab_type": "code",
        "outputId": "7fbd5cd2-a3de-4764-9015-91f76bcdc93e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "let keras = Python.import(\"keras\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "2020-06-01 21:32:53.985280: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTGf1sESCOUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "public protocol ImageTranslatorDataset {\n",
        "    associatedtype SourceDataSet: Collection\n",
        "    where SourceDataSet.Element == TensorPair<Float, Float>, SourceDataSet.Index == Int\n",
        "    init(batchSize: Int)\n",
        "    var training: Batcher<SourceDataSet> {get}\n",
        "    var test: Batcher<SourceDataSet> {get}\n",
        "}\n",
        "public typealias LazyTranslatorDataSet = LazyMapSequence<[URL], TensorPair<Float, Float>>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOFv9sKrHYoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "public struct ImageXDataSet: ImageTranslatorDataset {\n",
        "    public typealias SourceDataSet = LazyTranslatorDataSet\n",
        "    public var training: Batcher<SourceDataSet>\n",
        "    public var test: Batcher<SourceDataSet>\n",
        " \n",
        "    public enum ImageSize {\n",
        "        case full\n",
        "        case resized160\n",
        "        case resized320\n",
        "\n",
        "        var suffix: String {\n",
        "            switch self {\n",
        "            case .full: return \"\"\n",
        "            case .resized160: return \"-160\"\n",
        "            case .resized320: return \"-320\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    public init(batchSize: Int) {\n",
        "        var urls = [URL]()\n",
        "        var tensorPair = TensorPair<Float, Float>(first: Tensor(1.0), second: Tensor(1.0))\n",
        "        var c = urls.lazy.map {(url: URL) -> TensorPair<Float, Float> in tensorPair}\n",
        "        self.init(batchSize: batchSize, inputSize: .resized320, outputSize: 224)\n",
        "    }\n",
        "\n",
        "\n",
        "    public init(\n",
        "          batchSize: Int,\n",
        "          inputSize: ImageSize, outputSize: Int,\n",
        "          localStorageDirectory: URL = DatasetUtilities.defaultDirectory\n",
        "                  .appendingPathComponent(\"ImageX\", isDirectory: true)\n",
        "    ) {\n",
        "        var urls = [URL]()\n",
        "        var tensorPair = TensorPair<Float, Float>(first: Tensor(1.0), second: Tensor(1.0))\n",
        "        var c = urls.lazy.map {(url: URL) -> TensorPair<Float, Float> in tensorPair}\n",
        "        training = Batcher<SourceDataSet>(on: c, batchSize: 100)\n",
        "        test = Batcher<SourceDataSet>(on: c, batchSize: 100)\n",
        "        do {\n",
        "            training = Batcher<SourceDataSet>(\n",
        "                on: try self.loadImageXTrainingDirectory(\n",
        "                    inputSize: inputSize, outputSize: outputSize,\n",
        "                    localStorageDirectory: localStorageDirectory),\n",
        "                batchSize: batchSize, \n",
        "                shuffle: true)\n",
        "            // test = Batcher<SourceDataSet>(\n",
        "            //     on: try self.loadImagenetteValidationDirectory(\n",
        "            //         inputSize: inputSize, outputSize: outputSize,\n",
        "            //         localStorageDirectory: localStorageDirectory),\n",
        "            //     batchSize: batchSize)\n",
        "        } catch {\n",
        "            fatalError(\"Could not load ImageX dataset: \\(error)\")\n",
        "        }\n",
        "    }\n",
        "\n",
        "    func downloadImageXIfNotPresent(to directory: URL, size: ImageXDataSet.ImageSize) {\n",
        "        let downloadPath = directory.appendingPathComponent(\"imageX\").path\n",
        "        let directoryExists = FileManager.default.fileExists(atPath: downloadPath)\n",
        "        let contentsOfDir = try? FileManager.default.contentsOfDirectory(atPath: downloadPath)\n",
        "        let directoryEmpty = (contentsOfDir == nil) || (contentsOfDir!.isEmpty)\n",
        "\n",
        "        guard !directoryExists || directoryEmpty else { return }\n",
        "\n",
        "        // let location = URL(\n",
        "            // string: \"https://s3.amazonaws.com/fast-ai-imageclas/imagenette\\(size.suffix).tgz\")!\n",
        "\n",
        "        let location = URL(\n",
        "            string: \"https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/facades.tar\")!\n",
        "        let localURL = DatasetUtilities.downloadResource(\n",
        "            filename: \"facades\", fileExtension: \"tar\",\n",
        "            remoteRoot: location.deletingLastPathComponent(), localStorageDirectory: directory)\n",
        "        print(\"Local Storage URL\", localURL)\n",
        "    }\n",
        "\n",
        "    func exploreImageXDirectory(named name: String, in directory: URL, inputSize: ImageXDataSet.ImageSize) throws -> [URL] {\n",
        "        downloadImageXIfNotPresent(to: directory, size: inputSize)\n",
        "        // let path = directory.appendingPathComponent(\"imageX\\/\\(name)\")\n",
        "        // let dirContents = try FileManager.default.contentsOfDirectory(\n",
        "            // at: path, includingPropertiesForKeys: [.isDirectoryKey], options: [.skipsHiddenFiles])\n",
        "\n",
        "        var urls: [URL] = []\n",
        "        // for directoryURL in dirContents {\n",
        "        //     let subdirContents = try FileManager.default.contentsOfDirectory(\n",
        "        //         at: directoryURL, includingPropertiesForKeys: [.isDirectoryKey],\n",
        "        //         options: [.skipsHiddenFiles])\n",
        "        //     urls += subdirContents\n",
        "        // }\n",
        "        return urls\n",
        "    }\n",
        "\n",
        "    func parentLabel(url: URL) -> String {\n",
        "        return url.deletingLastPathComponent().lastPathComponent\n",
        "    }\n",
        "\n",
        "    func createLabelDict(urls: [URL]) -> [String: Int] {\n",
        "        let allLabels = urls.map(parentLabel)\n",
        "        let labels = Array(Set(allLabels)).sorted()\n",
        "        return Dictionary(uniqueKeysWithValues: labels.enumerated().map{ ($0.element, $0.offset) })\n",
        "    }\n",
        "\n",
        "    func loadImageXDirectory(\n",
        "        named name: String, in directory: URL, inputSize: ImageXDataSet.ImageSize, outputSize: Int,\n",
        "        labelDict: [String:Int]? = nil\n",
        "    ) throws -> LazyTranslatorDataSet {\n",
        "        let urls = try exploreImageXDirectory(named: name, in: directory, inputSize: inputSize)\n",
        "        let unwrappedLabelDict = labelDict ?? createLabelDict(urls: urls)\n",
        "        return urls.lazy.map { (url: URL) -> TensorPair<Float, Float> in\n",
        "            TensorPair<Float, Float>(\n",
        "                // split the image into two bits using Keras\n",
        "                first: Image(jpeg: url).resized(to: (outputSize, outputSize)).tensor / 255.0,\n",
        "                second: Image(jpeg: url).resized(to: (outputSize, outputSize)).tensor / 255.0)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    func loadImageXTrainingDirectory(\n",
        "        inputSize: ImageXDataSet.ImageSize, outputSize: Int, localStorageDirectory: URL, labelDict: [String:Int]? = nil\n",
        "    ) throws\n",
        "        -> LazyTranslatorDataSet\n",
        "    {\n",
        "        return try loadImageXDirectory(\n",
        "            named: \"train\", in: localStorageDirectory, inputSize: inputSize, outputSize: outputSize, labelDict: labelDict)\n",
        "    }\n",
        "\n",
        "    // func loadImagenetteValidationDirectory(\n",
        "    //     inputSize: ImageXDataSet.ImageSize, outputSize: Int, localStorageDirectory: URL, labelDict: [String:Int]? = nil\n",
        "    // ) throws\n",
        "    //     -> LazyTranslatorDataSet\n",
        "    // {\n",
        "    //     return try loadImagenetteDirectory(\n",
        "    //         named: \"val\", in: localStorageDirectory, inputSize: inputSize, outputSize: outputSize, labelDict: labelDict)\n",
        "    // }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNIjyP8FBoZH",
        "colab_type": "text"
      },
      "source": [
        "# public typealias LazyDataSet = LazyMapSequence<[URL], TensorPair<Float, Int32>>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09QKEqo0Vg_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "public struct Pix2PixDataSet: ImageClassificationDataset {\n",
        "    public typealias SourceDataSet = LazyDataSet\n",
        "    // let set = SourceDataSet()\n",
        "    // public typealias SourceDataSet = [[URL]:TensorPair<Float, Int32>]\n",
        "\n",
        "    // var paramDataset = [[URL]:TensorPair<Float,Int32>]().lazy\n",
        "    // let urls = [URL]()\n",
        "    // let lazyURLS = urls.lazy.map()\n",
        "    // let lazyURLs = urls.lazy.map {(url: URL) -> TensorPair<Float, Int32> in\n",
        "    //         TensorPair<Float, Int32>(\n",
        "    //             first: Image(jpeg: url),\n",
        "    //             second: Tensor<Int32>()\n",
        "    //         )}\n",
        "    // var pSet: Batcher<SourceDataSet> = Batcher(on: lazyURLs, batchSize: 100)\n",
        "    public var training: Batcher<SourceDataSet>\n",
        "    public var test: Batcher<SourceDataSet>\n",
        "    // let pair = TensorPair(first: Tensor<Float>(), second: Tensor<Int32>())\n",
        " \n",
        "    // var intArray = [Int32]()\n",
        "    // let testBatch: [URL:Int32] = [:]\n",
        "    // let testBatcher = Batcher(on: testBatch, batchSize: 100)\n",
        "    // let lazyMapSeq = Batcher(on: intArray!, batchSize: 0) \n",
        "\n",
        " \n",
        "    public enum ImageSize {\n",
        "        case full\n",
        "        case resized160\n",
        "        case resized320\n",
        "\n",
        "        var suffix: String {\n",
        "            switch self {\n",
        "            case .full: return \"\"\n",
        "            case .resized160: return \"-160\"\n",
        "            case .resized320: return \"-320\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    public init(batchSize: Int) {\n",
        "        var urls = [URL]()\n",
        "        var tensorPair = TensorPair<Float, Int32>(first: Tensor(1.0), second: Tensor(1))\n",
        "        var c = urls.lazy.map {(url: URL) -> TensorPair<Float, Int32> in tensorPair}\n",
        "        // training = Batcher<SourceDataSet>(on: c, batchSize: 100)\n",
        "        // test = Batcher<SourceDataSet>(on: c, batchSize: 100)\n",
        "        self.init(batchSize: batchSize, inputSize: .resized320, outputSize: 224)\n",
        "    }\n",
        "\n",
        "\n",
        "    public init(\n",
        "          batchSize: Int,\n",
        "          inputSize: ImageSize, outputSize: Int,\n",
        "          localStorageDirectory: URL = DatasetUtilities.defaultDirectory\n",
        "                  .appendingPathComponent(\"Imagenette\", isDirectory: true)\n",
        "    ) {\n",
        "        var urls = [URL]()\n",
        "        var tensorPair = TensorPair<Float, Int32>(first: Tensor(1.0), second: Tensor(1))\n",
        "        var c = urls.lazy.map {(url: URL) -> TensorPair<Float, Int32> in tensorPair}\n",
        "        training = Batcher<SourceDataSet>(on: c, batchSize: 100)\n",
        "        test = Batcher<SourceDataSet>(on: c, batchSize: 100)\n",
        "        do {\n",
        "            training = Batcher<SourceDataSet>(\n",
        "                on: try self.loadImagenetteTrainingDirectory(\n",
        "                    inputSize: inputSize, outputSize: outputSize,\n",
        "                    localStorageDirectory: localStorageDirectory),\n",
        "                batchSize: batchSize, \n",
        "                shuffle: true)\n",
        "            test = Batcher<SourceDataSet>(\n",
        "                on: try self.loadImagenetteValidationDirectory(\n",
        "                    inputSize: inputSize, outputSize: outputSize,\n",
        "                    localStorageDirectory: localStorageDirectory),\n",
        "                batchSize: batchSize)\n",
        "        } catch {\n",
        "            fatalError(\"Could not load Imagenette dataset: \\(error)\")\n",
        "        }\n",
        "    }\n",
        "\n",
        "    func downloadImagenetteIfNotPresent(to directory: URL, size: Pix2PixDataSet.ImageSize) {\n",
        "        let downloadPath = directory.appendingPathComponent(\"imagenette\\(size.suffix)\").path\n",
        "        let directoryExists = FileManager.default.fileExists(atPath: downloadPath)\n",
        "        let contentsOfDir = try? FileManager.default.contentsOfDirectory(atPath: downloadPath)\n",
        "        let directoryEmpty = (contentsOfDir == nil) || (contentsOfDir!.isEmpty)\n",
        "\n",
        "        guard !directoryExists || directoryEmpty else { return }\n",
        "\n",
        "        let location = URL(\n",
        "            string: \"https://s3.amazonaws.com/fast-ai-imageclas/imagenette\\(size.suffix).tgz\")!\n",
        "        let _ = DatasetUtilities.downloadResource(\n",
        "            filename: \"imagenette\\(size.suffix)\", fileExtension: \"tgz\",\n",
        "            remoteRoot: location.deletingLastPathComponent(), localStorageDirectory: directory)\n",
        "    }\n",
        "\n",
        "    func exploreImagenetteDirectory(named name: String, in directory: URL, inputSize: Pix2PixDataSet.ImageSize) throws -> [URL] {\n",
        "        downloadImagenetteIfNotPresent(to: directory, size: inputSize)\n",
        "        let path = directory.appendingPathComponent(\"imagenette\\(inputSize.suffix)/\\(name)\")\n",
        "        let dirContents = try FileManager.default.contentsOfDirectory(\n",
        "            at: path, includingPropertiesForKeys: [.isDirectoryKey], options: [.skipsHiddenFiles])\n",
        "\n",
        "        var urls: [URL] = []\n",
        "        for directoryURL in dirContents {\n",
        "            let subdirContents = try FileManager.default.contentsOfDirectory(\n",
        "                at: directoryURL, includingPropertiesForKeys: [.isDirectoryKey],\n",
        "                options: [.skipsHiddenFiles])\n",
        "            urls += subdirContents\n",
        "        }\n",
        "        return urls\n",
        "    }\n",
        "\n",
        "    func parentLabel(url: URL) -> String {\n",
        "        return url.deletingLastPathComponent().lastPathComponent\n",
        "    }\n",
        "\n",
        "    func createLabelDict(urls: [URL]) -> [String: Int] {\n",
        "        let allLabels = urls.map(parentLabel)\n",
        "        let labels = Array(Set(allLabels)).sorted()\n",
        "        return Dictionary(uniqueKeysWithValues: labels.enumerated().map{ ($0.element, $0.offset) })\n",
        "    }\n",
        "\n",
        "    func loadImagenetteDirectory(\n",
        "        named name: String, in directory: URL, inputSize: Pix2PixDataSet.ImageSize, outputSize: Int,\n",
        "        labelDict: [String:Int]? = nil\n",
        "    ) throws -> LazyDataSet {\n",
        "        let urls = try exploreImagenetteDirectory(named: name, in: directory, inputSize: inputSize)\n",
        "        let unwrappedLabelDict = labelDict ?? createLabelDict(urls: urls)\n",
        "        return urls.lazy.map { (url: URL) -> TensorPair<Float, Int32> in\n",
        "            TensorPair<Float, Int32>(\n",
        "                first: Image(jpeg: url).resized(to: (outputSize, outputSize)).tensor / 255.0,\n",
        "                second: Tensor<Int32>(Int32(unwrappedLabelDict[parentLabel(url: url)]!))\n",
        "            )    \n",
        "        }\n",
        "    }\n",
        "\n",
        "    func loadImagenetteTrainingDirectory(\n",
        "        inputSize: Pix2PixDataSet.ImageSize, outputSize: Int, localStorageDirectory: URL, labelDict: [String:Int]? = nil\n",
        "    ) throws\n",
        "        -> LazyDataSet\n",
        "    {\n",
        "        return try loadImagenetteDirectory(\n",
        "            named: \"train\", in: localStorageDirectory, inputSize: inputSize, outputSize: outputSize, labelDict: labelDict)\n",
        "    }\n",
        "\n",
        "    func loadImagenetteValidationDirectory(\n",
        "        inputSize: Pix2PixDataSet.ImageSize, outputSize: Int, localStorageDirectory: URL, labelDict: [String:Int]? = nil\n",
        "    ) throws\n",
        "        -> LazyDataSet\n",
        "    {\n",
        "        return try loadImagenetteDirectory(\n",
        "            named: \"val\", in: localStorageDirectory, inputSize: inputSize, outputSize: outputSize, labelDict: labelDict)\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nS2btci0xD5W",
        "colab_type": "code",
        "outputId": "e9a00030-5337-4f0d-81df-820860e8d910",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "let pixDataSet = Pix2PixDataSet(batchSize: 100)\n",
        "print(\"data set training size\", pixDataSet.training.count)\n",
        "print(\"data set test size\", pixDataSet.test.count)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data set training size 129\r\n",
            "data set test size 5\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4rOER-xiLry",
        "colab_type": "code",
        "outputId": "b0357337-c945-4463-b61f-fd2a99a4b809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "let xDataSet = ImageXDataSet(batchSize: 100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading resource: facades\r\n",
            "Local Storage URL file:///root/.cache/swift-models/datasets/ImageX/facades/\r\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}